---
title: "'Scalar mice': data preprocessing"
author: "Mathias Stoeber"
date: "8/19/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Initialise
```{r message=FALSE}
# Load packages
library(readbulk)
library(mousetrap)
library(dplyr)
library(ggplot2)

# Read multiple data files (from raw OpenSesame output)
raw_data <-
  readbulk::read_opensesame(directory = "csv/", extension = ".csv")
```

## Preprocessing I:  The raw data
```{r}
# Exclude all trials from the training block
raw_data <- raw_data %>%
  filter(!is.na(count_trials_test))

# Record some metadata
n_before <- nrow(raw_data)
n_wrong_responses <- nrow(filter(raw_data, correct == 0))
n_correct_responses <- nrow(filter(raw_data, correct == 1))
n_slow_responses <-
  nrow(filter(raw_data, initiation_time_tracking2_test > 500))
n_swift_responses <-
  nrow(filter(raw_data, initiation_time_tracking2_test < 500))
```

### By-subject wrong responses
```{r}
(
  stats_errors <- raw_data %>%
    filter(correct == 0) %>%
    group_by(subject_nr) %>%
    summarise(
      error_count = n(),
      error_percentage = round((n() / n_before) * 100, digits = 2)
    )
)
```

### By-subject slow responses
```{r}
(
  stats_slow <- raw_data %>%
    filter(initiation_time_tracking2_test > 500) %>%
    group_by(subject_nr) %>%
    summarise(
      slow_count = n(),
      slow_percentage = round((n() / n_before) * 100, digits = 2)
    )
)
```

### Exclude wrong and slow responses
Tomlinson says: "We removed incorrect responses from all conditions."
```{r}
# Exclude wrong responses
raw_data <- raw_data %>% filter(correct != 0)
```

Tomlinson says: "[Some] responses had initiation times greater than 500 ms. These responses were also removed." 
```{r}
# Exclude slow responses
raw_data <- raw_data %>% filter(initiation_time_tracking2_test < 500)
```

### Transforming the data into a mousetrap data object
Note that there were 3 mousetrap-os items in the experiment, we now need to concatenate the output of two of them going forward (this will give us the complete trajectories).
```{r}
mtdata <- mt_import_mousetrap(
  raw_data,
  xpos_label = c(
    "xpos_tracking1_test",
    "xpos_tracking2_test"
  ),
  ypos_label = c(
    "ypos_tracking1_test",
    "ypos_tracking2_test"
  ),
  timestamps_label = c(
    "timestamps_tracking1_test",
    "timestamps_tracking2_test"
  )
)
```

## Preprocessing II: The wonky check
```{r}
# Right side up
# This just flips all trajectories vertically.
mtdata <- mt_remap_symmetric(mtdata)

# Start-align
# This aligns all trajectories so that each originates from the same point
mtdata <- mt_align_start(mtdata)
```

### Visually check for wonky trajectories
This step may take some time to compute.
If you want to run it, you have to switch the **chunk option** 'eval' to 'TRUE'.
```{r, eval=FALSE}
 mt_plot_per_trajectory(mtdata,
                        file="trajectories.pdf",
                        use="trajectories",
                        verbose = TRUE)
```
Have a look at the PDF that was just created in your working directory and
record the IDs of wonky-looking trajectories in the vector "wonkies" below.
Tip: On the Mac, make use of Preview's "Contact Sheet" mode with [Option+Command+6].

### Exclude wonkies
```{r}
 wonkies <- c(
 #Enter the wonkies' trial IDs here
   94,147,149,177,218,226,272
)

#Record number of wonkies
n_wonkies <- length(wonkies)

# Insert id column to filter wonkies by
mtdata$data$wonkcheck_id <- seq_along(mtdata$data$count_trials_test)

# Label wonky trials
mtdata$data$is_wonky <- FALSE
mtdata$data$is_wonky[mtdata$data$wonkcheck_id %in% wonkies] <- TRUE

# By-subject wonkies
(
  stats_wonkies <- mtdata$data %>%
  filter(is_wonky == TRUE) %>% 
  group_by(subject_nr) %>%
  summarise(wonky_count = n(),
            wonky_percentage = round((n() / n_before) * 100, digits = 2))
)

# Remove wonky trials
mtdata <- mt_subset(mtdata, subset = is_wonky == FALSE)
```

## Preprocessing III: The mtdata object
Perform the usual calculations on the raw trajectories
```{r}
mtdata <- mt_derivatives(mtdata)
mtdata <- mt_measures(mtdata)
mtdata <- mt_time_normalize(mtdata)
mtdata <- mt_derivatives(mtdata, use = "tn_trajectories", save_as = "tn_trajectories")
```

### Create a data.frame containing the results
Don't forget to enter the desired mouse tracking measurements plus any additional variables below! I pre-loaded the function with some examples.
Note that the *main* mousetrap item in our experiment was called 'tracking2_test'. Where applicable, we're interested in the variables belonging to this one, e.g. 'intitiation_time_tracking2_test'.
```{r}
results <- mt_export_long(
  mtdata,
  use = "measures",
  use_variables = c("AUC", "AD"),
  use2_variables = c(
    "response",
    "stimulus",
    "sentence_type",
    "subject_nr",
    "correct",
    "correct_response",
    "initiation_time_tracking2_test"
  )
)
```

```{r eval=FALSE, include=FALSE}
# Optional: write the results to file
write.csv(results, file = "results.csv", row.names = FALSE)
```

### Gather more metadata
#### 1. Sampling resolution check
The 'desired' value below has to correspond to the sampling rate value set in OpenSesame.
```{r}
res_check <- mt_check_resolution(mtdata, use = "trajectories", desired = 10)
```
`r round(res_check$relative_frequencies_desired[2] * 100, digits = 2)` % of all samples were made at the desired rate of 100 Hz.

#### 2. Bimodality check
A distribution is considered bimodal if BC > 0.555.
Remember to enter the measures you want checked for bimodality below!
```{r}
# Standardize AUC per participant
mtdataBC <- mt_standardize(mtdata, use_variables = "AUC", within = "subject_nr")

(
  b_coefs <- mt_check_bimodality(
  mtdataBC,
  use = "measures",
  use_variables = c("MAD", "AUC"),
  methods = "BC",
  grouping_variables = NULL
  )
)
```

#### 3. Exclusion percentages
Calculate percentage of wrong responses
```{r}
wrong_response_percentage <- round((n_wrong_responses / n_before) * 100, digits = 2)
```
`r wrong_response_percentage` % of (remaining) trials were incorrect responses.

Calculate percentage of slow responses
```{r}
slow_response_percentage <- round((n_slow_responses / n_before) * 100, digits = 2)
```
`r slow_response_percentage` % of (remaining) trials were initiated too slowly.

Calculate percentage of wonky responses
```{r}
wonky_response_percentage <- round((n_wonkies / n_before) * 100, digits = 2)
```
`r wonky_response_percentage` % of (remaining) trials were wonkies.

Calculate number and percentage of total exclusions
```{r}
n_total_exclusions <- n_before - nrow(results)

total_exclusion_percentage <- round(
  ((n_before - nrow(results)) / n_before) * 100, 
  digits = 2)
```
Of all trials , `r total_exclusion_percentage` % had to be excluded.

